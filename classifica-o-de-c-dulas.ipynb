{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport csv \nimport cv2\nimport os\nimport numpy as np\nfrom numpy import mean\nfrom numpy import std\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.applications.vgg16 import VGG16\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.optimizers import AdamW\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import models,layers\nfrom sklearn.model_selection import KFold\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Input, InputLayer, Flatten\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.preprocessing import image\nfrom tensorflow.keras.optimizers import Adam\nfrom  matplotlib import pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"id":"eXWgCjxAyo6_","execution":{"iopub.status.busy":"2022-09-02T16:54:27.895248Z","iopub.execute_input":"2022-09-02T16:54:27.896395Z","iopub.status.idle":"2022-09-02T16:54:30.413354Z","shell.execute_reply.started":"2022-09-02T16:54:27.896299Z","shell.execute_reply":"2022-09-02T16:54:30.412081Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"base_dir = '../input/dataset-cedulas/DeformedNotes_AME'","metadata":{"id":"4lbrhyJhWrSp","outputId":"5bc0bedb-173b-4668-a47f-2d5714e97137","execution":{"iopub.status.busy":"2022-09-02T16:54:30.422319Z","iopub.execute_input":"2022-09-02T16:54:30.423232Z","iopub.status.idle":"2022-09-02T16:54:30.430802Z","shell.execute_reply.started":"2022-09-02T16:54:30.423188Z","shell.execute_reply":"2022-09-02T16:54:30.428455Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def readImages( path, X_train, Y_train  ):\n  print(\"Loading data...\")\n\n  files = [ f for f in listdir(path) if isfile(join(path,f)) ]\n  files.sort()\n  #print(files)\n\n  print( len(files), \"images...\" )\n\n  for i in range( len(files) ):\t\t#  i = identificador ----- 0 - qnt de imagens\n    img = cv2.imread(join(path,files[i]),0)\n    img = cv2.resize(img, (150, 150))\n    X_train.append( img )\n\n    name = files[i].split(\"_\")\n    name = name[3].split(\".\")\n    if( int(name[0]) == 1 ):\n      Y_train.append( 0 )\n    elif( int(name[0]) == 2 ):\n      Y_train.append( 1 )\n    elif( int(name[0]) == 5 ):\n      Y_train.append( 2 )\n    elif( int(name[0]) == 10 ):\n      Y_train.append( 3 )\n    elif( int(name[0]) == 20 ):\n      Y_train.append( 4 )\n    elif( int(name[0]) == 50 ):\n      Y_train.append( 5 )\n    elif( int(name[0]) == 100 ):\n      Y_train.append( 6 )\n    elif( int(name[0]) == 200 ):\n      Y_train.append( 7 )\n    else:\n      print(\".: \", i, \" - \", name)\n\n  X_train = np.array(X_train)\n  Y_train = np.array(Y_train)\n  print('X_data shape:', X_train.shape)\n  print('Y_data shape:', Y_train.shape)\n#  print('Y_data shape:', Y_train)\n\n  # one hot encode target values\n  Y_train = to_categorical(Y_train)\n  print(Y_train.shape)\n  print(Y_train[12])\n\n  # cv2.imshow(img)\n\n  # convert from integers to floats\n  X_train = X_train.astype('float32')\n  print(X_train.shape)\n  \n  # normalize to range 0-1\n  X_train = X_train / 255.0\n  print(X_train.shape)\n  \n  del files\n\n  return X_train, Y_train","metadata":{"id":"W2pCVmA94Iay","execution":{"iopub.status.busy":"2022-09-02T16:54:30.433212Z","iopub.execute_input":"2022-09-02T16:54:30.434260Z","iopub.status.idle":"2022-09-02T16:54:30.455407Z","shell.execute_reply.started":"2022-09-02T16:54:30.434200Z","shell.execute_reply":"2022-09-02T16:54:30.453813Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"  X_train = []\n  Y_train = []\n\n  X_train, Y_train = readImages(base_dir, X_train, Y_train)\n  print(X_train.shape)\n  print(Y_train.shape)","metadata":{"id":"BT9ZZU4-lHz5","outputId":"d3ceccdf-213a-4d08-bddf-36c61cd80267","execution":{"iopub.status.busy":"2022-09-02T16:54:30.460379Z","iopub.execute_input":"2022-09-02T16:54:30.462000Z","iopub.status.idle":"2022-09-02T16:57:33.058144Z","shell.execute_reply.started":"2022-09-02T16:54:30.461964Z","shell.execute_reply":"2022-09-02T16:57:33.056819Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loading data...\n16152 images...\nX_data shape: (16152, 150, 150)\nY_data shape: (16152,)\n(16152, 7)\n[0. 0. 0. 0. 0. 1. 0.]\n(16152, 150, 150)\n(16152, 150, 150)\n(16152, 150, 150)\n(16152, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = X_train.reshape(-1, 150, 150, 1)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:57:33.060196Z","iopub.execute_input":"2022-09-02T16:57:33.061035Z","iopub.status.idle":"2022-09-02T16:57:33.067777Z","shell.execute_reply.started":"2022-09-02T16:57:33.060938Z","shell.execute_reply":"2022-09-02T16:57:33.066483Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"INPUT_SHAPE = (150, 150, 1)\nNUM_CLASSES = 7\n\ndef define_model():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=INPUT_SHAPE))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dropout(rate=0.25))\n    model.add(Dense(NUM_CLASSES, activation='softmax'))\n    \n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"id":"doZmKJ0bXV9a","execution":{"iopub.status.busy":"2022-09-02T16:57:33.069328Z","iopub.execute_input":"2022-09-02T16:57:33.070240Z","iopub.status.idle":"2022-09-02T16:57:33.083215Z","shell.execute_reply.started":"2022-09-02T16:57:33.070189Z","shell.execute_reply":"2022-09-02T16:57:33.082037Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = define_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-02T16:57:33.084921Z","iopub.execute_input":"2022-09-02T16:57:33.086263Z","iopub.status.idle":"2022-09-02T16:57:34.111852Z","shell.execute_reply.started":"2022-09-02T16:57:33.086221Z","shell.execute_reply":"2022-09-02T16:57:34.110550Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2022-09-02 16:57:33.138784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.148148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.148960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.150271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-02 16:57:33.150627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA ","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 150, 150, 32)      320       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 37, 37, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n_________________________________________________________________\nflatten (Flatten)            (None, 41472)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               5308544   \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 903       \n=================================================================\nTotal params: 5,402,119\nTrainable params: 5,402,119\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"node zero\n2022-09-02 16:57:33.151393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.152092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.633906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.634909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.635714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-02 16:57:33.636361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# evaluate a model using k-fold cross-validation\ndef evaluate_model(dataX, dataY, n_folds=5):\n    print(\"Evaluating model...\")\n    scores, histories = list(), list()\n    # prepare cross validation\n    kfold = KFold(n_folds, shuffle=True, random_state=1)\n    c = 1\n    # enumerate splits\n    for train_ix, test_ix in kfold.split(dataX):\n        print(\"fold \", c)\n        # define model\n\n        model = define_model()\n        \n        # select rows for train and test\n        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n        # fit model\n\n        history = model.fit(trainX, trainY, epochs=30, batch_size=8, validation_data=(testX, testY), verbose=1)\n        \n        # evaluate model\n        _, acc = model.evaluate(testX, testY, verbose=1)\n        print('> %.3f' % (acc * 100.0))\n\n        # stores scores\n        scores.append(acc)\n        histories.append(history)\n        c += 1\n\n    return scores, histories","metadata":{"id":"m2oPew3RpeNf","execution":{"iopub.status.busy":"2022-09-02T16:57:34.113805Z","iopub.execute_input":"2022-09-02T16:57:34.114945Z","iopub.status.idle":"2022-09-02T16:57:34.127371Z","shell.execute_reply.started":"2022-09-02T16:57:34.114898Z","shell.execute_reply":"2022-09-02T16:57:34.125928Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)\n\nprint(\"Model setting...\")\ndefine_model()\n\nprint(\"Training and evaluating model...\")\nscores, histories = evaluate_model(X_train, Y_train, n_folds=5)\n\nprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))","metadata":{"id":"RQfow-5NcN9G","execution":{"iopub.status.busy":"2022-09-02T16:57:34.129319Z","iopub.execute_input":"2022-09-02T16:57:34.130935Z","iopub.status.idle":"2022-09-02T17:29:16.734960Z","shell.execute_reply.started":"2022-09-02T16:57:34.130805Z","shell.execute_reply":"2022-09-02T17:29:16.732544Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(16152, 150, 150, 1)\n(16152, 7)\nModel setting...\nTraining and evaluating model...\nEvaluating model...\nfold  1\n","output_type":"stream"},{"name":"stderr","text":"2022-09-02 16:57:34.695967: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1162890000 exceeds 10% of free system memory.\n2022-09-02 16:57:36.042799: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1162890000 exceeds 10% of free system memory.\n2022-09-02 16:57:37.010982: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2022-09-02 16:57:37.832454: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1616/1616 [==============================] - 15s 8ms/step - loss: 1.8227 - accuracy: 0.2336 - val_loss: 1.7906 - val_accuracy: 0.2510\nEpoch 2/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7941 - accuracy: 0.2484 - val_loss: 1.7800 - val_accuracy: 0.2491\nEpoch 3/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7778 - accuracy: 0.2589 - val_loss: 1.7634 - val_accuracy: 0.2696\nEpoch 4/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.7541 - accuracy: 0.2734 - val_loss: 1.7423 - val_accuracy: 0.2804\nEpoch 5/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7075 - accuracy: 0.2973 - val_loss: 1.6740 - val_accuracy: 0.3132\nEpoch 6/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.6286 - accuracy: 0.3326 - val_loss: 1.6055 - val_accuracy: 0.3265\nEpoch 7/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.5242 - accuracy: 0.3839 - val_loss: 1.4958 - val_accuracy: 0.3962\nEpoch 8/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.3999 - accuracy: 0.4527 - val_loss: 1.3909 - val_accuracy: 0.4287\nEpoch 9/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.2556 - accuracy: 0.5191 - val_loss: 1.2537 - val_accuracy: 0.5166\nEpoch 10/30\n1616/1616 [==============================] - 14s 9ms/step - loss: 1.1011 - accuracy: 0.5811 - val_loss: 1.1546 - val_accuracy: 0.5723\nEpoch 11/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.9612 - accuracy: 0.6388 - val_loss: 1.0076 - val_accuracy: 0.6339\nEpoch 12/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.8134 - accuracy: 0.7002 - val_loss: 0.9572 - val_accuracy: 0.6472\nEpoch 13/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.6880 - accuracy: 0.7484 - val_loss: 0.8266 - val_accuracy: 0.7060\nEpoch 14/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.5636 - accuracy: 0.7992 - val_loss: 0.7952 - val_accuracy: 0.7184\nEpoch 15/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.4605 - accuracy: 0.8369 - val_loss: 0.7763 - val_accuracy: 0.7298\nEpoch 16/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.3711 - accuracy: 0.8667 - val_loss: 0.7890 - val_accuracy: 0.7416\nEpoch 17/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.3213 - accuracy: 0.8873 - val_loss: 0.7658 - val_accuracy: 0.7552\nEpoch 18/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2491 - accuracy: 0.9160 - val_loss: 0.7685 - val_accuracy: 0.7589\nEpoch 19/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2180 - accuracy: 0.9276 - val_loss: 0.8066 - val_accuracy: 0.7719\nEpoch 20/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1635 - accuracy: 0.9454 - val_loss: 0.7736 - val_accuracy: 0.7855\nEpoch 21/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1599 - accuracy: 0.9468 - val_loss: 0.7810 - val_accuracy: 0.7784\nEpoch 22/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1325 - accuracy: 0.9559 - val_loss: 0.8238 - val_accuracy: 0.7824\nEpoch 23/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 0.1166 - accuracy: 0.9639 - val_loss: 0.7795 - val_accuracy: 0.8007\nEpoch 24/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1066 - accuracy: 0.9656 - val_loss: 0.7381 - val_accuracy: 0.8131\nEpoch 25/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1018 - accuracy: 0.9669 - val_loss: 0.7543 - val_accuracy: 0.8124\nEpoch 26/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9735 - val_loss: 0.7773 - val_accuracy: 0.8124\nEpoch 27/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0822 - accuracy: 0.9732 - val_loss: 0.7940 - val_accuracy: 0.8044\nEpoch 28/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 0.7818 - val_accuracy: 0.8112\nEpoch 29/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.8113 - val_accuracy: 0.8041\nEpoch 30/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.8470 - val_accuracy: 0.8066\n101/101 [==============================] - 1s 9ms/step - loss: 0.8470 - accuracy: 0.8066\n> 80.656\nfold  2\n","output_type":"stream"},{"name":"stderr","text":"2022-09-02 17:04:01.815091: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1162890000 exceeds 10% of free system memory.\n2022-09-02 17:04:03.147202: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1162890000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 1.8318 - accuracy: 0.2347 - val_loss: 1.7983 - val_accuracy: 0.2498\nEpoch 2/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.8047 - accuracy: 0.2419 - val_loss: 1.7943 - val_accuracy: 0.2498\nEpoch 3/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7974 - accuracy: 0.2491 - val_loss: 1.7792 - val_accuracy: 0.2600\nEpoch 4/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.7866 - accuracy: 0.2549 - val_loss: 1.7689 - val_accuracy: 0.2699\nEpoch 5/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7703 - accuracy: 0.2628 - val_loss: 1.7505 - val_accuracy: 0.2606\nEpoch 6/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7443 - accuracy: 0.2755 - val_loss: 1.7238 - val_accuracy: 0.2950\nEpoch 7/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.6879 - accuracy: 0.3059 - val_loss: 1.6455 - val_accuracy: 0.3414\nEpoch 8/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.5902 - accuracy: 0.3518 - val_loss: 1.5136 - val_accuracy: 0.3977\nEpoch 9/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.4698 - accuracy: 0.4150 - val_loss: 1.3948 - val_accuracy: 0.4633\nEpoch 10/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.3265 - accuracy: 0.4863 - val_loss: 1.3204 - val_accuracy: 0.4909\nEpoch 11/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.1740 - accuracy: 0.5484 - val_loss: 1.1224 - val_accuracy: 0.5806\nEpoch 12/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.0100 - accuracy: 0.6215 - val_loss: 1.0212 - val_accuracy: 0.6171\nEpoch 13/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.8525 - accuracy: 0.6904 - val_loss: 0.9389 - val_accuracy: 0.6608\nEpoch 14/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.7187 - accuracy: 0.7360 - val_loss: 0.8612 - val_accuracy: 0.6852\nEpoch 15/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.5872 - accuracy: 0.7883 - val_loss: 0.7898 - val_accuracy: 0.7286\nEpoch 16/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.4946 - accuracy: 0.8256 - val_loss: 0.7310 - val_accuracy: 0.7555\nEpoch 17/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.4049 - accuracy: 0.8619 - val_loss: 0.7177 - val_accuracy: 0.7673\nEpoch 18/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.3142 - accuracy: 0.8906 - val_loss: 0.6974 - val_accuracy: 0.7781\nEpoch 19/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.2726 - accuracy: 0.9058 - val_loss: 0.7216 - val_accuracy: 0.7803\nEpoch 20/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2315 - accuracy: 0.9201 - val_loss: 0.7206 - val_accuracy: 0.7920\nEpoch 21/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1956 - accuracy: 0.9343 - val_loss: 0.6809 - val_accuracy: 0.8131\nEpoch 22/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1549 - accuracy: 0.9479 - val_loss: 0.7780 - val_accuracy: 0.8001\nEpoch 23/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.1472 - accuracy: 0.9508 - val_loss: 0.7096 - val_accuracy: 0.8081\nEpoch 24/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1338 - accuracy: 0.9542 - val_loss: 0.7184 - val_accuracy: 0.8128\nEpoch 25/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0995 - accuracy: 0.9686 - val_loss: 0.7185 - val_accuracy: 0.8223\nEpoch 26/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1060 - accuracy: 0.9659 - val_loss: 0.7144 - val_accuracy: 0.8251\nEpoch 27/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1039 - accuracy: 0.9639 - val_loss: 0.7187 - val_accuracy: 0.8140\nEpoch 28/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0817 - accuracy: 0.9728 - val_loss: 0.7226 - val_accuracy: 0.8223\nEpoch 29/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0886 - accuracy: 0.9717 - val_loss: 0.8145 - val_accuracy: 0.8131\nEpoch 30/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 0.7547 - val_accuracy: 0.8242\n101/101 [==============================] - 1s 7ms/step - loss: 0.7547 - accuracy: 0.8242\n> 82.420\nfold  3\n","output_type":"stream"},{"name":"stderr","text":"2022-09-02 17:10:20.885999: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1162980000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 1.8295 - accuracy: 0.2452 - val_loss: 1.7917 - val_accuracy: 0.2585\nEpoch 2/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.7988 - accuracy: 0.2447 - val_loss: 1.7880 - val_accuracy: 0.2693\nEpoch 3/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7778 - accuracy: 0.2680 - val_loss: 1.7597 - val_accuracy: 0.2663\nEpoch 4/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.7525 - accuracy: 0.2709 - val_loss: 1.7185 - val_accuracy: 0.2854\nEpoch 5/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.6965 - accuracy: 0.2945 - val_loss: 1.6414 - val_accuracy: 0.3502\nEpoch 6/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.6185 - accuracy: 0.3334 - val_loss: 1.6082 - val_accuracy: 0.3260\nEpoch 7/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.5276 - accuracy: 0.3818 - val_loss: 1.4685 - val_accuracy: 0.4508\nEpoch 8/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.4104 - accuracy: 0.4435 - val_loss: 1.3549 - val_accuracy: 0.4988\nEpoch 9/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.2814 - accuracy: 0.5018 - val_loss: 1.2329 - val_accuracy: 0.5344\nEpoch 10/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.1576 - accuracy: 0.5547 - val_loss: 1.1516 - val_accuracy: 0.5672\nEpoch 11/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.0216 - accuracy: 0.6165 - val_loss: 0.9953 - val_accuracy: 0.6331\nEpoch 12/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.8902 - accuracy: 0.6607 - val_loss: 0.9234 - val_accuracy: 0.6635\nEpoch 13/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.7692 - accuracy: 0.7164 - val_loss: 0.9208 - val_accuracy: 0.6684\nEpoch 14/30\n1616/1616 [==============================] - 14s 9ms/step - loss: 0.6553 - accuracy: 0.7565 - val_loss: 0.8245 - val_accuracy: 0.7118\nEpoch 15/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.5609 - accuracy: 0.7969 - val_loss: 0.7759 - val_accuracy: 0.7433\nEpoch 16/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.4819 - accuracy: 0.8229 - val_loss: 0.8527 - val_accuracy: 0.7105\nEpoch 17/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.4074 - accuracy: 0.8542 - val_loss: 0.7469 - val_accuracy: 0.7604\nEpoch 18/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.3468 - accuracy: 0.8762 - val_loss: 0.7303 - val_accuracy: 0.7687\nEpoch 19/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.2883 - accuracy: 0.9012 - val_loss: 0.7192 - val_accuracy: 0.7793\nEpoch 20/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.2560 - accuracy: 0.9096 - val_loss: 0.7653 - val_accuracy: 0.7721\nEpoch 21/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2363 - accuracy: 0.9170 - val_loss: 0.7199 - val_accuracy: 0.7783\nEpoch 22/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1955 - accuracy: 0.9343 - val_loss: 0.7629 - val_accuracy: 0.7824\nEpoch 23/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1696 - accuracy: 0.9430 - val_loss: 0.7814 - val_accuracy: 0.7957\nEpoch 24/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1704 - accuracy: 0.9422 - val_loss: 0.7560 - val_accuracy: 0.8006\nEpoch 25/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1476 - accuracy: 0.9492 - val_loss: 0.7897 - val_accuracy: 0.8028\nEpoch 26/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1328 - accuracy: 0.9555 - val_loss: 0.8162 - val_accuracy: 0.7950\nEpoch 27/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 0.1184 - accuracy: 0.9599 - val_loss: 0.7687 - val_accuracy: 0.8037\nEpoch 28/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.1079 - accuracy: 0.9641 - val_loss: 0.7952 - val_accuracy: 0.8087\nEpoch 29/30\n1616/1616 [==============================] - 14s 9ms/step - loss: 0.1062 - accuracy: 0.9646 - val_loss: 0.7703 - val_accuracy: 0.8248\nEpoch 30/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0912 - accuracy: 0.9700 - val_loss: 0.8092 - val_accuracy: 0.8111\n101/101 [==============================] - 1s 8ms/step - loss: 0.8092 - accuracy: 0.8111\n> 81.115\nfold  4\nEpoch 1/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 1.8183 - accuracy: 0.2344 - val_loss: 1.8009 - val_accuracy: 0.2421\nEpoch 2/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7916 - accuracy: 0.2546 - val_loss: 1.7869 - val_accuracy: 0.2672\nEpoch 3/30\n1616/1616 [==============================] - 14s 9ms/step - loss: 1.7734 - accuracy: 0.2617 - val_loss: 1.7656 - val_accuracy: 0.2805\nEpoch 4/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7414 - accuracy: 0.2808 - val_loss: 1.7213 - val_accuracy: 0.3000\nEpoch 5/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.6706 - accuracy: 0.3228 - val_loss: 1.6127 - val_accuracy: 0.3579\nEpoch 6/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.5577 - accuracy: 0.3732 - val_loss: 1.4900 - val_accuracy: 0.4115\nEpoch 7/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.4263 - accuracy: 0.4415 - val_loss: 1.3713 - val_accuracy: 0.4684\nEpoch 8/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.2750 - accuracy: 0.5079 - val_loss: 1.2410 - val_accuracy: 0.5455\nEpoch 9/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.1177 - accuracy: 0.5783 - val_loss: 1.1395 - val_accuracy: 0.5709\nEpoch 10/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.9650 - accuracy: 0.6443 - val_loss: 1.0187 - val_accuracy: 0.6300\nEpoch 11/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.8131 - accuracy: 0.7006 - val_loss: 0.9009 - val_accuracy: 0.6669\nEpoch 12/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.6803 - accuracy: 0.7515 - val_loss: 0.8046 - val_accuracy: 0.7152\nEpoch 13/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.5657 - accuracy: 0.7974 - val_loss: 0.7657 - val_accuracy: 0.7294\nEpoch 14/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.4668 - accuracy: 0.8332 - val_loss: 0.7515 - val_accuracy: 0.7365\nEpoch 15/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.3844 - accuracy: 0.8646 - val_loss: 0.6999 - val_accuracy: 0.7734\nEpoch 16/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.3202 - accuracy: 0.8861 - val_loss: 0.6510 - val_accuracy: 0.7916\nEpoch 17/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2581 - accuracy: 0.9105 - val_loss: 0.7040 - val_accuracy: 0.7889\nEpoch 18/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.2230 - accuracy: 0.9228 - val_loss: 0.6685 - val_accuracy: 0.7870\nEpoch 19/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1964 - accuracy: 0.9345 - val_loss: 0.6618 - val_accuracy: 0.7988\nEpoch 20/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1670 - accuracy: 0.9419 - val_loss: 0.7049 - val_accuracy: 0.8031\nEpoch 21/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.1559 - accuracy: 0.9492 - val_loss: 0.6807 - val_accuracy: 0.8161\nEpoch 22/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1293 - accuracy: 0.9570 - val_loss: 0.6496 - val_accuracy: 0.8149\nEpoch 23/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1124 - accuracy: 0.9615 - val_loss: 0.6753 - val_accuracy: 0.8167\nEpoch 24/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0947 - accuracy: 0.9714 - val_loss: 0.6476 - val_accuracy: 0.8180\nEpoch 25/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0994 - accuracy: 0.9674 - val_loss: 0.7450 - val_accuracy: 0.8059\nEpoch 26/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0960 - accuracy: 0.9677 - val_loss: 0.7151 - val_accuracy: 0.8260\nEpoch 27/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0825 - accuracy: 0.9740 - val_loss: 0.6841 - val_accuracy: 0.8248\nEpoch 28/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0831 - accuracy: 0.9720 - val_loss: 0.7103 - val_accuracy: 0.8217\nEpoch 29/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0799 - accuracy: 0.9753 - val_loss: 0.7100 - val_accuracy: 0.8285\nEpoch 30/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.6827 - val_accuracy: 0.8322\n101/101 [==============================] - 1s 7ms/step - loss: 0.6827 - accuracy: 0.8322\n> 83.220\nfold  5\nEpoch 1/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 1.8114 - accuracy: 0.2452 - val_loss: 1.7954 - val_accuracy: 0.2474\nEpoch 2/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.7837 - accuracy: 0.2633 - val_loss: 1.7896 - val_accuracy: 0.2489\nEpoch 3/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 1.7640 - accuracy: 0.2698 - val_loss: 1.7655 - val_accuracy: 0.2656\nEpoch 4/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.7292 - accuracy: 0.2830 - val_loss: 1.7134 - val_accuracy: 0.2656\nEpoch 5/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.6575 - accuracy: 0.3207 - val_loss: 1.6306 - val_accuracy: 0.3266\nEpoch 6/30\n1616/1616 [==============================] - 14s 9ms/step - loss: 1.5508 - accuracy: 0.3746 - val_loss: 1.5090 - val_accuracy: 0.4059\nEpoch 7/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.4153 - accuracy: 0.4498 - val_loss: 1.3894 - val_accuracy: 0.4684\nEpoch 8/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 1.2488 - accuracy: 0.5228 - val_loss: 1.2314 - val_accuracy: 0.5387\nEpoch 9/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 1.0709 - accuracy: 0.6001 - val_loss: 1.1281 - val_accuracy: 0.5830\nEpoch 10/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.9038 - accuracy: 0.6675 - val_loss: 1.0215 - val_accuracy: 0.6220\nEpoch 11/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.7523 - accuracy: 0.7249 - val_loss: 0.9448 - val_accuracy: 0.6539\nEpoch 12/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.6047 - accuracy: 0.7832 - val_loss: 0.8835 - val_accuracy: 0.6876\nEpoch 13/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.4981 - accuracy: 0.8251 - val_loss: 0.9019 - val_accuracy: 0.6876\nEpoch 14/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.3867 - accuracy: 0.8611 - val_loss: 0.8854 - val_accuracy: 0.7043\nEpoch 15/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.3099 - accuracy: 0.8937 - val_loss: 0.7795 - val_accuracy: 0.7449\nEpoch 16/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2429 - accuracy: 0.9180 - val_loss: 0.8510 - val_accuracy: 0.7372\nEpoch 17/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.2073 - accuracy: 0.9281 - val_loss: 0.8719 - val_accuracy: 0.7375\nEpoch 18/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.1702 - accuracy: 0.9475 - val_loss: 0.8345 - val_accuracy: 0.7523\nEpoch 19/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1445 - accuracy: 0.9535 - val_loss: 0.9110 - val_accuracy: 0.7560\nEpoch 20/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.1312 - accuracy: 0.9574 - val_loss: 0.8427 - val_accuracy: 0.7706\nEpoch 21/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.1097 - accuracy: 0.9632 - val_loss: 0.8494 - val_accuracy: 0.7703\nEpoch 22/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0968 - accuracy: 0.9704 - val_loss: 0.9384 - val_accuracy: 0.7675\nEpoch 23/30\n1616/1616 [==============================] - 14s 8ms/step - loss: 0.0848 - accuracy: 0.9719 - val_loss: 0.8537 - val_accuracy: 0.7873\nEpoch 24/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0779 - accuracy: 0.9753 - val_loss: 0.9473 - val_accuracy: 0.7780\nEpoch 25/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0647 - accuracy: 0.9798 - val_loss: 0.8904 - val_accuracy: 0.7839\nEpoch 26/30\n1616/1616 [==============================] - 13s 8ms/step - loss: 0.0540 - accuracy: 0.9826 - val_loss: 0.8946 - val_accuracy: 0.7830\nEpoch 27/30\n1616/1616 [==============================] - 12s 7ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 1.0790 - val_accuracy: 0.7638\nEpoch 28/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0580 - accuracy: 0.9824 - val_loss: 0.8957 - val_accuracy: 0.7895\nEpoch 29/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0448 - accuracy: 0.9858 - val_loss: 0.9884 - val_accuracy: 0.7771\nEpoch 30/30\n1616/1616 [==============================] - 12s 8ms/step - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.9205 - val_accuracy: 0.7901\n101/101 [==============================] - 1s 7ms/step - loss: 0.9205 - accuracy: 0.7901\n> 79.009\nAccuracy: mean=81.284 std=1.458, n=5\n","output_type":"stream"}]}]}